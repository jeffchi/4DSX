{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "ename": "SyntaxError", 
                    "evalue": "Missing parentheses in call to 'print' (<ipython-input-2-5e518770bc74>, line 33)", 
                    "traceback": [
                        "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-5e518770bc74>\"\u001b[0;36m, line \u001b[0;32m33\u001b[0m\n\u001b[0;31m    print 'There is no parameter input.'\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'\n"
                    ], 
                    "output_type": "error"
                }
            ], 
            "source": "# import the required lib\nimport datetime\nimport re\nimport time\n\n'''\nTo get query condition string from reading the file :singleDBCondition\nand handle it to gain all parameters by split function\n'''\nDB_CONN_ID = ''\nEND_TIME = ''\nINTERVAL = 0\nSTART_TIME = ''\nREPORT_TYPE = ''\nISOK_ALL_PARA = 1\n\ndef handle_query_condition():\n    # To declare below variables are global variables\n    global DB_CONN_ID\n    global END_TIME\n    global INTERVAL\n    global START_TIME\n    global REPORT_TYPE\n    global ISOK_ALL_PARA\n    \n    # To read parameters from singleDBCondition file\n    where_cause = !cat singleDBCondition\n    where_cause = re.search(r'DB_CONN_ID\\s?=\\s?.+END_TIME\\s?=\\s?.+INTERVAL\\s?=\\s?.+REPORT_TYPE\\s?=\\s?.+', where_cause[0])\n\n    if (where_cause != None):\n        all_vars = where_cause.group().split(' ')\n    if len(all_vars) == 0:\n        print 'There is no parameter input.'\n        ISOK_ALL_PARA = 0\n    elif len(all_vars) != 4:\n        print 'The format of parameters is error.'\n        ISOK_ALL_PARA = 0\n    else:# len(all_vars) == 4\n        # To get DB_CONN_ID\n        if (re.search(r'DB_CONN_ID\\s?=\\s?(.+)', all_vars[0]) == None):\n            print 'The DB_CONN_ID is empty.'\n            ISOK_ALL_PARA = 0\n        else:\n            DB_CONN_ID = re.search(r'DB_CONN_ID\\s?=\\s?(.+)', all_vars[0]).group(1)\n            \n        # To get the value of INTERVAL\n        if (re.search(r'INTERVAL\\s?=\\s?([0-9]+$)', all_vars[2]) == None):\n            print 'The format of INTERVAL error.'\n            ISOK_ALL_PARA = 0\n        else:\n            INTERVAL = int(re.search(r'(\\d+)', all_vars[2]).group())\n            if (INTERVAL > 100):  # most get 100 data\n                INTERVAL = 100\n\n        # To get START_TIME according to END_TIME\n        if (re.search(r'(\\d{4}-\\d{1,2}-\\d{1,2})', all_vars[1]) == None) | ( re.search(r'(\\d{1,2}:\\d{1,2}:\\d{1,2})', all_vars[1]) == None):\n            print 'The format of END_TIME error.'\n            ISOK_ALL_PARA = 0\n        else:\n            END_TIME = re.search(r'(\\d{4}-\\d{1,2}-\\d{1,2})', all_vars[1]).group() + ' ' + re.search( r'(\\d{1,2}:\\d{1,2}:\\d{1,2})', all_vars[1]).group()\n            datetime_tuple = time.strptime(END_TIME, '%Y-%m-%d %H:%M:%S')\n            # To slice datetime_tuple to gain exact time data\n            year, month, day, hour, minute, second = datetime_tuple[:6]\n            final_time = datetime.datetime(year, month, day, hour, minute, second) + datetime.timedelta(hours = -INTERVAL)\n            # To transfer the datetime fields to string\n            START_TIME = final_time.strftime('%Y-%m-%d %H:%M:%S')\n\n        # To get the value of REPORT_TYPE\n        if (re.search(r'REPORT_TYPE\\s?=\\s?(.+)', all_vars[3]) == None):\n            print 'The format of REPORT_TYPE error.'\n            ISOK_ALL_PARA = 0\n        else:\n            REPORT_TYPE = re.search(r'REPORT_TYPE\\s?=\\s?(.+)', all_vars[3]).group(1).upper()\n            if (REPORT_TYPE != 'ALL' and REPORT_TYPE != 'RESOURCE' and REPORT_TYPE != 'CPU' and REPORT_TYPE != 'MEMORY' and REPORT_TYPE != 'LOG'):\n                print 'The format of REPORT_TYPE error.'\n\n'''\nThis function is to get all datatime string according to the result \nqueried from database.\n\nThe variable ori_datetime_str is a dictionary and its data \nfrom the combination of hour_list and date_all, which will \nbe used for judging whether some data exists in it or not.\n'''\ndef get_original_datatime_str(date_all, hour_list):\n    ori_datetime_str = {}\n    for indx in range(len(hour_list)):\n        tmp_date_str = date_all[indx].encode('unicode-escape').decode('string_escape')\n        tmp_hour_str = str(hour_list[indx])\n        tmp_datetime_str = ''\n        if(len(tmp_hour_str) == 1):#Change 1:00:00 into 01:00:00\n            tmp_hour_str = '0' + tmp_hour_str\n        tmp_datetime_str = tmp_date_str + ' ' + tmp_hour_str + ':00:00'\n        ori_datetime_str[tmp_datetime_str] = indx\n    return ori_datetime_str"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#import the required libs\nimport numpy as np\nimport pylab as pl\nfrom scipy.interpolate import spline\n\n#To get all query conditions\nhandle_query_condition()\n\nif(ISOK_ALL_PARA and (REPORT_TYPE == 'ALL' or REPORT_TYPE == 'RESOURCE')):\n    #Get data from the target database to assemble a data frame that will be used for the following graphs\n    dataframe_hour = %sql select char(date(collected)) as date,hour(collected) as hours,sum(total_cpu_usec_delta)/1000000.0 as cpu_sec,sum(logical_reads_delta) as logical_reads,sum(PHYSICAL_READS_DELTA) as physical_reads,sum(total_act_time)/(sum(act_aborted_total)+sum(act_completed_total)) as avg_activity_time_msec,sum(act_completed_total_delta) as activities from ibm_dsm_views.throughput_all where dbconn_id='{DB_CONN_ID}' and collected >= '{START_TIME}' and collected < '{END_TIME}' group by date(collected),hour(collected) order by date,hours\n    if dataframe_hour.empty:\n        print 'For RESOURCE: The query result is empty, please check your query parameters.\\n'\n    else:\n        #Get the hour data as x-axis from the data frame\n        x_hour = dataframe_hour['HOURS']\n        #Get the CPU_SEC data as y-axis from the data frame\n        y_cpu_sec = dataframe_hour['CPU_SEC']\n        y_cpu_sec_list = list(y_cpu_sec)\n        \n        y_logical_reads = dataframe_hour['LOGICAL_READS']\n        y_logical_reads_list = list(y_logical_reads)\n       \n        y_physical_reads = dataframe_hour['PHYSICAL_READS']\n        y_physical_reads_list = list(y_physical_reads)\n        \n        y_avg_act = dataframe_hour['AVG_ACTIVITY_TIME_MSEC']\n        y_avg_act_list = list(y_avg_act)\n        \n        x_ticks = []\n        x_ticks_lables = []\n        \n        x_hour_list = list(x_hour) #here x_hour is a python list\n        date_all = list(dataframe_hour['DATE'].values)\n        \n        ori_datetime_str = get_original_datatime_str(date_all,x_hour_list)\n        \n        '''\n        When the data queried is not equal to the requirement. Filling missing data \n        into the list x_hour_list,date_all and y_ticks.\n        '''\n        if (len(x_hour_list) < INTERVAL):\n            #Transfer datatime data into time tuple for getting its' timestamp\n            tm_tuple = time.strptime(START_TIME,'%Y-%m-%d %H:%M:%S')\n            min_timestamp = time.mktime(tm_tuple)\n            \n            tmp_tuple = time.strptime(END_TIME,'%Y-%m-%d %H:%M:%S')\n            max_timestamp = time.mktime(tmp_tuple)\n            '''\n            Get the difference between the max_timestamp and min_timestamp \n            which will be used for gaining all date and hour including the missing\n            '''\n            hour_diff = int((max_timestamp - min_timestamp)/3600)\n            #clear date_all\n            date_all = []\n            #clear x_hour_list\n            x_hour_list = []\n            #clear y_ticks\n            y_cpu_sec_list = []\n            y_logical_reads_list = []\n            y_physical_reads_list = []\n            y_avg_act_list = []\n            \n            #Reassign three var above\n            for tmp_id in range(hour_diff):\n                tmp_st = min_timestamp + tmp_id * 3600\n                #Trans timestamp to datetime string\n                tmp_datetime = datetime.datetime.fromtimestamp(tmp_st)\n                tmp_datetime_str = tmp_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")\n                tmp_date_str = tmp_datetime_str[0:10]\n                tmp_hour_str = tmp_datetime_str[11:13]\n                date_all.append(tmp_date_str)\n                x_hour_list.append(tmp_hour_str)\n                '''\n                Below code is for handling y-axis's data\n                If there is no data at this hour,0.0 will be filled into\n                '''\n                if tmp_datetime_str in ori_datetime_str:\n                    tmp_index = ori_datetime_str[tmp_datetime_str]\n                    y_cpu_sec_list.append(list(y_cpu_sec)[tmp_index])\n                    y_logical_reads_list.append(list(y_logical_reads)[tmp_index])\n                    y_physical_reads_list.append(list(y_physical_reads)[tmp_index])\n                    y_avg_act_list.append(list(y_avg_act)[tmp_index])\n                else:\n                    y_cpu_sec_list.append(0.0)\n                    y_logical_reads_list.append(0)\n                    y_physical_reads_list.append(0)\n                    y_avg_act_list.append(0)\n            \n            y_cpu_sec = np.asarray(y_cpu_sec_list)\n            y_logical_reads = np.asarray(y_logical_reads_list)\n            y_physical_reads = np.asarray(y_physical_reads_list)\n            y_avg_act = np.asarray(y_avg_act_list)\n        #previous date string value as a reference data\n        pre_date_str = str(date_all[0])\n        \n        for dateIdx in range(len(date_all)):\n            #Get the data for the x-axis ticks\n            x_ticks.append(float('%0.1f' % dateIdx))\n            '''\n            Get the data for the lable of x-axis\n            If the label existed in the list x_ticks_lables,\n            put hour_str into x_ticks_lables \n            otherwise,put date_lables into x_ticks_lables\n            '''\n            hour_str = str(x_hour_list[dateIdx])\n            date_str = str(date_all[dateIdx])\n            x_lables = date_str + ' ' + hour_str\n            if (dateIdx == 0):\n                x_ticks_lables.append(x_lables)\n            else:#dateIdx > 0\n                if (pre_date_str == date_str):\n                    x_ticks_lables.append(hour_str)\n                else:\n                    pre_date_str = date_str\n                    x_ticks_lables.append(x_lables)\n        \n        ###First graph###    \n        #Declare a Sketchpad as the first graph\n        fig = pl.figure()\n        #Declare an ax container as the first drawing paper\n        ax = fig.add_subplot(111)\n        #Set the size of the Sketchpad depending on the size of the data\n        data_size = len(x_ticks)\n        if(data_size <= 20):\n            fig.set_size_inches(12,6)\n        elif(data_size <= 40):\n            fig.set_size_inches(16,6)\n        elif(data_size <= 60):\n            fig.set_size_inches(18,7)\n        elif(data_size <=100):\n            fig.set_size_inches(22,7)\n\n        #Set the title for the first graph\n        figure_title = 'CPU Usage by Hour\\n'\n        pl.title(figure_title,fontsize=14,fontweight='bold')\n       \n        #Get the DATE data as x-axis's label the data frame\n        #dateTmp=dataframe_hour['DATE'][0]\n        x_lable = 'Hours'\n        #Set x-axis label\n        pl.xlabel(x_lable)\n        #Set y-axis label\n        pl.ylabel(u'CPU_SEC(s)')\n        #Set grid line style according to your requirement\n        pl.grid(True,ls='--',color='#a6266e',alpha =0.05)\n        pl.xticks(x_ticks,x_ticks_lables,rotation=90)\n        \n        for id in range(len(y_cpu_sec_list)):\n            if(y_cpu_sec_list[id] == 0.0):#If no data,drawing a empty circle\n                pl.scatter(x_ticks[id], y_cpu_sec_list[id], c = '', marker = 'o', edgecolors = 'r', s = 50)\n            else:\n                pl.scatter(x_ticks[id], y_cpu_sec_list[id],c = '#2c628b') \n                pl.text(x_ticks[id], y_cpu_sec_list[id], '%.2f' % y_cpu_sec_list[id], fontsize = 9)\n        \n        #x_hour_isSorted=True do nothing, otherwise, handle data sperately by day\n        xnew_hour = []\n        ynew_cpu_sec = []\n       \n        if(len(x_hour_list) >= 3):\n            xnew_hour = np.linspace(np.asarray(x_ticks).min(), np.asarray(x_ticks).max(), np.asarray(x_ticks).size*20) \n            #Handle the data of new y axis data\n            ynew_cpu_sec = spline(np.asarray(x_ticks), y_cpu_sec,xnew_hour)\n            \n            ynew_cpu_sec_list = list(ynew_cpu_sec)\n            #No negative value for y-axis\n            for y_idx in range(len(ynew_cpu_sec_list)):\n                if (ynew_cpu_sec_list[y_idx] < 0.0):\n                    ynew_cpu_sec_list[y_idx] = 0.0\n            ynew_cpu_sec = np.asarray(ynew_cpu_sec_list)     \n            \n            #Fill the gragh according to your requirement\n            pl.fill_between(xnew_hour, ynew_cpu_sec, where=(xnew_hour.min()<xnew_hour) & (xnew_hour<xnew_hour.max()), color='#a6266e', alpha =0.15)\n            #First draw a smooth line chart using xnew_hour and ynew_memory\n            pl.plot(xnew_hour, ynew_cpu_sec, color = '#a6266e')\n            #Set y-axis value range according to your data\n            start_value = ynew_cpu_sec.min()- ynew_cpu_sec.min() / 20\n            start_value = float('%0.2f' % start_value)\n            end_value = ynew_cpu_sec.max() + ynew_cpu_sec.max() / 20\n            end_value = float('%0.2f' % end_value)\n            pl.ylim(float('%0.2f' % start_value), float('%0.2f' % end_value))\n        else:\n            y_cpu_sec_list = list(map(int, y_cpu_sec_list))\n            pl.yticks(y_cpu_sec_list, rotation=0)\n        pl.show()\n\n        ###Second graph###\n        #Get the LOGICAL_READS data as the left y-axis from the data frame\n        log_mil = False\n        if y_logical_reads.max() > 1000000:\n            log_mil = True\n            y_logical_reads = y_logical_reads/1000000\n        \n        phy_mil = False\n        if y_physical_reads.max() > 1000000:\n            phy_mil = True\n            y_physical_reads = y_physical_reads/1000000\n        \n        #Declare a Sketchpad as the second graph\n        fig = pl.figure()\n        #Declare an ax1 container as the second drawing paper\n        ax1 = fig.add_subplot(111)\n        #Set the size of the Sketchpad\n        if(data_size <= 20):\n            fig.set_size_inches(12,3)\n        elif(data_size <= 40):\n            fig.set_size_inches(16,3)\n        elif(data_size <= 60):\n            fig.set_size_inches(18,3)\n        elif(data_size <=100):\n            fig.set_size_inches(22,3)\n\n        #Set title for the second graph\n        figure_title = 'I/O Consumption by Hour\\n'\n        pl.title(figure_title, fontsize = 14,fontweight = 'bold')\n        #Set x-axis label\n        pl.xlabel(x_lable, fontsize = 12)\n        pl.xticks(x_ticks, x_ticks_lables, rotation=90)\n        pl.bar(np.asarray(x_ticks)-0.15, y_logical_reads, width=0.3, color = '#2c628b',alpha=0.5)\n        #Set y-axis label\n        if (log_mil == True):\n            pl.ylabel(u'LOGICAL_READS(mil times)')\n        else:\n            pl.ylabel(u'LOGICAL_READS(times)')\n        pl.grid(True, ls = '-.', color = '#a6266e', linewidth = '.5', alpha = 0.3)\n        #Set ax1 and ax2 to the same x-axis\n        ax2 = ax1.twinx()\n\n        #Draw the second graph using x_hour and y_physical_reads\n        pl.bar(np.asarray(x_ticks)+0.15, y_physical_reads, width=0.3, color = '#4c78fb', alpha=0.6)\n        #Set y-axis lab\n        if (phy_mil==True):\n            pl.ylabel(u'PHYSICAL_READS(mil times)')\n        else:\n            pl.ylabel(u'PHYSICAL_READS(times)')\n\n        #Set legend for the ax1 contioner\n        ax1.legend(['LOGICAL_READS'], loc='upper right', bbox_to_anchor=(0.5,1.14), ncol=1)\n        #Set legend for the ax2 contioner\n        ax2.legend(['PHYSICAL_READS'], loc='upper right', bbox_to_anchor=(0.7,1.14), fancybox=True, shadow=True,ncol=1)\n        #Set grid format\n        pl.grid(True,ls = '-.', color = '#a6266e', linewidth = '0.5', alpha=0.3)\n        #Show the second graph\n        pl.show()\n        \n        ###The third graph###\n        #Declare a Sketchpad as the first graph\n        fig = pl.figure()\n        #Declare an ax container as the first drawing paper\n        ax = fig.add_subplot(111)\n        #Set the size of the Sketchpad\n        if(data_size <= 20):\n            fig.set_size_inches(12,2)\n        elif(data_size <= 40):\n            fig.set_size_inches(16,2)\n        elif(data_size <= 60):\n            fig.set_size_inches(18,2)\n        elif(data_size <= 100):\n            fig.set_size_inches(22,2)\n\n        #Set the title for the first graph\n        figure_title = 'Average Activity Time by Hour'\n        pl.title(figure_title, fontsize = 14, fontweight = 'bold')\n       \n        #Get the DATE data as x-axis's label the data frame\n        #Set x-axis label\n        pl.xlabel(x_lable, fontsize = 12)\n        #Set y-axis label\n        pl.ylabel(u'AVG_ACTIVITY_TIME_MSEC', fontsize = 9)\n        #Set grid line style according to your requirement\n        pl.grid(True, ls = '--', color= '#a6266e', alpha = 0.05)\n        pl.xticks(x_ticks, x_ticks_lables, rotation = 90)\n        \n        for id in range(len(y_avg_act_list)):\n            if(y_avg_act_list[id] == 0.0):#If no data,drawing a empty circle\n                pl.scatter(x_ticks[id], y_avg_act_list[id], c = '', marker = 'o', edgecolors = 'r', s = 50)\n            else:\n                pl.scatter(x_ticks[id], y_avg_act_list[id], c = '#2c628b') \n                pl.text(x_ticks[id], y_avg_act_list[id], '%.0f' % y_avg_act_list[id], fontsize = 9)\n        \n        #x_hour_isSorted=True do nothing, otherwise, handle data sperately by day\n        xnew_hour = []\n        ynew_cpu_sec = []\n        \n        if(len(x_hour_list) >= 3):\n            xnew_hour = np.linspace(np.asarray(x_ticks).min(), np.asarray(x_ticks).max(), np.asarray(x_ticks).size*20) \n            #Handle the data of new y axis data\n            ynew_avg_act = spline(np.asarray(x_ticks), y_avg_act, xnew_hour)\n            ynew_avg_act_list = list(ynew_avg_act)\n            #No negative value for y-axis\n            for y_idx in range(len(ynew_avg_act_list)):\n                if (ynew_avg_act_list[y_idx] < 0.0):\n                    ynew_avg_act_list[y_idx] = 0.0\n            ynew_avg_act = np.asarray(ynew_avg_act_list) \n            #Fill the gragh according to your requirement\n            pl.fill_between(xnew_hour,ynew_avg_act,where=(xnew_hour.min()<xnew_hour) & (xnew_hour<xnew_hour.max()), color = '#a6266e', alpha = 0.15)\n            #First draw a smooth line chart using xnew_hour and ynew_memory\n            pl.plot(xnew_hour, ynew_avg_act, color = '#a6266e')\n            #Set y-axis value range according to your data\n            start_value = ynew_avg_act.min() - ynew_avg_act.min() / 2\n            start_value = float('%0.2f' % start_value)\n            end_value = ynew_avg_act.max() + ynew_avg_act.max() / 2\n            end_value = float('%0.2f' % end_value)\n            pl.ylim(float('%0.2f' % start_value), float('%0.2f' % end_value))\n        else:\n            y_avg_act_list = list(map(int, y_avg_act_list))\n            pl.yticks(y_avg_act_list, rotation = 0)\n        pl.show()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#import the required libs\nimport numpy as np\nimport pylab as pl\nfrom scipy.interpolate import spline\n\n#To get all query conditions\nhandle_query_condition()\n\nif(ISOK_ALL_PARA and (REPORT_TYPE == 'ALL' or REPORT_TYPE == 'CPU')):\n    #Get data from the target database to assemble a data frame that will be used for the following graphs\n    dataframe_hour = %sql select char(date(collected)) as date, hour(collected) as hours, sum(db2_cpu_user_delta) as db2_cpu_user,  100*sum(db2_cpu_user_delta)/(sum(cpu_user_delta) + sum(cpu_system_delta) + sum(cpu_iowait_delta)+ sum(cpu_idle_delta)) as db2_cpu_user_percent, sum(db2_cpu_system_delta) as db2_cpu_system,  100*sum(db2_cpu_system_delta)/(sum(cpu_user_delta) + sum(cpu_system_delta) + sum(cpu_iowait_delta)+ sum(cpu_idle_delta)) as db2_cpu_system_percent,sum(cpu_user_delta) as cpu_user,  100*sum(cpu_user_delta)/(sum(cpu_user_delta) + sum(cpu_system_delta) + sum(cpu_iowait_delta)+ sum(cpu_idle_delta)) as cpu_user_percent,sum(cpu_system_delta) as cpu_system,  100*sum(cpu_system_delta)/(sum(cpu_user_delta) + sum(cpu_system_delta) + sum(cpu_iowait_delta)+ sum(cpu_idle_delta)) as cpu_system_percent from IBM_DSM_VIEWS.THROUGHPUT_SYSTEM where dbconn_id='{DB_CONN_ID}' and collected >= '{START_TIME}' and collected < '{END_TIME}' group by date(collected),hour(collected) order by date,hours\n    if dataframe_hour.empty:\n        print 'For CPU: The query result is empty, please check your query parameters.\\n'\n    else:\n        #Get the hour data as x-axis from the data frame\n        x_hour = dataframe_hour['HOURS']\n        #Get the db2_cpu_user_percent data as top y-axis of the first graph from the data frame\n        y_db2_user = dataframe_hour['DB2_CPU_USER_PERCENT']\n        y_db2_user_list = []\n        #Get the db2_cpu_system_percent data as bottom y-axis of the first graph from the data frame\n        y_db2_sys = dataframe_hour['DB2_CPU_SYSTEM_PERCENT']\n        y_db2_sys_list = []\n        #Get the cpu_user_percent data as top y-axis of the second graph from the data frame\n        y_cpu_user = dataframe_hour['CPU_USER_PERCENT']\n        y_cpu_user_list = []\n        #Get the cpu_system_percent data as bottom y-axis of the second graph from the data frame\n        y_cpu_sys = dataframe_hour['CPU_SYSTEM_PERCENT']\n        y_cpu_sys_list = []\n        \n        x_ticks = []\n        x_ticks_lables = []\n        x_hour_list = list(x_hour)\n        date_all = list(dataframe_hour['DATE'].values)\n        \n        ori_datetime_str = get_original_datatime_str(date_all, x_hour_list)\n        \n        '''\n        When the data queried is not equal to the requirement. Filling missing data \n        into the list x_hour_list,date_all and y_ticks.\n        '''\n        if (len(x_hour_list) < INTERVAL):\n            #Transfer datatime data into time tuple for getting its' timestamp\n            tm_tuple = time.strptime(START_TIME, '%Y-%m-%d %H:%M:%S')\n            min_timestamp = time.mktime(tm_tuple)\n            \n            tmp_tuple = time.strptime(END_TIME, '%Y-%m-%d %H:%M:%S')\n            max_timestamp = time.mktime(tmp_tuple)            \n\n            '''\n            Get the difference between the max_timestamp and min_timestamp \n            which will be used for gaining all date and hour including the missing\n            '''\n            hour_diff = int((max_timestamp - min_timestamp) / 3600)\n            #clear date_all\n            date_all = []\n            #clear x_hour_list\n            x_hour_list = []\n            \n            #Reassign three var above\n            for tmp_id in range(hour_diff):\n                tmp_st = min_timestamp + tmp_id * 3600\n                #Trans timestamp to datetime string\n                tmp_datetime = datetime.datetime.fromtimestamp(tmp_st)\n                tmp_datetime_str = tmp_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")\n                tmp_date_str = tmp_datetime_str[0:10]\n                tmp_hour_str = tmp_datetime_str[11:13]\n                date_all.append(tmp_date_str)\n                x_hour_list.append(tmp_hour_str)\n                '''\n                Below code is for handling y-axis's data\n                If there is no data at this hour,0.0 will be filled into\n                '''\n                if tmp_datetime_str in ori_datetime_str:\n                    tmp_index = ori_datetime_str[tmp_datetime_str]\n                    y_db2_user_list.append(list(y_db2_user)[tmp_index])\n                    y_db2_sys_list.append(list(y_db2_sys)[tmp_index])\n                    y_cpu_user_list.append(list(y_cpu_user)[tmp_index])\n                    y_cpu_sys_list.append(list(y_cpu_sys)[tmp_index])\n                else:\n                    y_db2_user_list.append(0)\n                    y_db2_sys_list.append(0)\n                    y_cpu_user_list.append(0)\n                    y_cpu_sys_list.append(0)\n            y_db2_user = np.asarray(y_db2_user_list)\n            y_db2_sys = np.asarray(y_db2_sys_list)\n            y_cpu_user = np.asarray(y_cpu_user_list)\n            y_cpu_sys = np.asarray(y_cpu_sys_list)\n            \n        #previous date string value as a reference data\n        pre_date_str = str(date_all[0])\n        \n        for dateIdx in range(len(date_all)):\n            #Get the data for the x-axis ticks\n            x_ticks.append(float('%0.1f' % dateIdx))\n            '''\n            Get the data for the lable of x-axis\n            If the label existed in the list x_ticks_lables,\n            put hour_str into x_ticks_lables \n            otherwise,put date_lables into x_ticks_lables\n            '''\n            hour_str = str(x_hour_list[dateIdx])\n            date_str = str(date_all[dateIdx])\n            x_lables = date_str + ' ' + hour_str\n            if (dateIdx == 0):\n                x_ticks_lables.append(x_lables)\n            else:#dateIdx > 0\n                if (pre_date_str == date_str):\n                    x_ticks_lables.append(hour_str)\n                else:\n                    pre_date_str = date_str\n                    x_ticks_lables.append(x_lables)\n        \n        #Declare a Sketchpad including two graphs of left and right distribution\n        fig = pl.figure()\n        \n        #Declare an ax1 container as the left drawing paper\n        ax1 = fig.add_subplot(111)\n        #Set the size of the Sketchpad\n        data_size = len(x_ticks)\n        if(data_size <= 20):\n            fig.set_size_inches(12,6)\n        elif(data_size <= 40):\n            fig.set_size_inches(16,6)\n        elif(data_size <= 60):\n            fig.set_size_inches(18,7)\n        elif(data_size <=100):\n            fig.set_size_inches(22,7)\n        #Set the title for the left graph\n        figure_title = 'CPU Utilization by Hour\\n'\n        pl.title(figure_title, fontsize=14, fontweight='bold')\n        \n        pl.xticks(x_ticks, x_ticks_lables, rotation=90)\n       \n        #Set y-axis label\n        pl.ylabel(u'CPU %')\n        #Set x-axis label\n        x_lable= 'Hours'\n        pl.xlabel(x_lable)\n        x_hour = np.asarray(x_ticks)\n        #Draw the top y-axis of the upper graph\n        pl.bar(x_hour - 0.2, y_db2_user, width = 0.4, align = 'center', color = '#60bdae')\n        #Draw the bottom y-axis of the upper graph\n        pl.bar(x_hour - 0.2, y_db2_sys, width=0.4, align = 'center', color = '#a6266e',bottom = y_db2_user)\n        #Draw the top y-axis of the lower graph\n        pl.bar(x_hour + 0.2, y_cpu_user, width=0.4, color = '#4c78fb')\n        #Draw the bottom y-axis of the lower graph\n        pl.bar(x_hour + 0.2, y_cpu_sys, width=0.4, color = '#2c628b', bottom = y_cpu_user)\n        \n        pl.yticks(np.arange(0, 101, 10))\n\n        #Set the legends for the both graphs\n        box = ax1.get_position()\n        ax1.set_position([box.x0, box.y0 + box.height * 0.1, box.width, box.height * 0.9])\n        ax1.legend(['DB2_CPU_USER_PERCENT', 'DB2_CPU_SYSTEM_PERCENT', 'CPU_USER_PERCENT', 'CPU_SYSTEM_PERCENT'], fontsize = 9, loc = 'upper center', bbox_to_anchor=(0.5,1.06), fancybox = True, shadow = True, ncol = 4)\n        #Set grid format for ax1\n        pl.grid(True, ls = '-.', color = '#a6266e', linewidth = '0.2', alpha = 0.3)\n\n        #Show all graphs\n        pl.show()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#import the required lib\nimport numpy as np\nimport pylab as pl\nfrom scipy.interpolate import spline\n\n#To get all query conditions\nhandle_query_condition()\n\n#To get data and draw graph by data.\nif(ISOK_ALL_PARA and (REPORT_TYPE == 'ALL' or REPORT_TYPE == 'MEMORY')):\n    #Get data from the target database to assemble a data frame that will be used for the following graph\n    dataframe_hour = %sql select char(date(collected)) as date,hour(collected) as hours,dec(max(memory_pool_used_gb),17,2) as memory_usage_gb from IBM_DSM_VIEWS.MEM_DB_TOTAL_USED where dbconn_id='{DB_CONN_ID}' and collected >= '{START_TIME}' and collected < '{END_TIME}' group by date(collected),hour(collected) order by date,hours\n\n    if dataframe_hour.empty:\n        print 'For MEMORY: The query result is empty, please check your query parameters.\\n'\n    else:\n        #Get the hour data as x-axis from the data frame and convert the data into a numpy array\n        x_hour = dataframe_hour['HOURS'].values #here x_hour is a numpy narray\n        #Get the memory_usage_gb data as y-axis from the data frame and convert the data into a numpy array\n        y_memory = dataframe_hour['MEMORY_USAGE_GB'].values\n        #Define a empty var x_ticks to store x-axis ticks(marks)\n        x_ticks = []\n        #Define a empty var x_ticks_lables to restore x-axis labels\n        x_ticks_lables = []\n        #Define a empty var y_ticks to store y-axis ticks(marks)\n        y_memory_list = list(y_memory)\n        \n        x_hour_list = list(x_hour) #here x_hour is a python list\n        date_all = list(dataframe_hour['DATE'].values)\n        \n        ori_datetime_str = get_original_datatime_str(date_all, x_hour_list)\n        \n        '''\n        When the data queried is not equal to the requirement. Filling missing data \n        into the list x_hour_list,date_all and y_memory_list.\n        '''\n        if (len(x_hour_list) < INTERVAL):\n            #Transfer datatime data into time tuple for getting its' timestamp\n            tm_tuple = time.strptime(START_TIME, '%Y-%m-%d %H:%M:%S')\n            min_timestamp = time.mktime(tm_tuple)\n            \n            tmp_tuple = time.strptime(END_TIME, '%Y-%m-%d %H:%M:%S')\n            max_timestamp = time.mktime(tmp_tuple)\n            \n            '''\n            Get the difference between the max_timestamp and min_timestamp \n            which will be used for gaining all date and hour including the missing\n            '''\n            hour_diff = int((max_timestamp - min_timestamp) / 3600)\n            # To clear date_all\n            date_all = []\n            # To clear x_hour_list\n            x_hour_list = []\n            # To declare a new list to store y_memory data temporarily\n            tmp_y_ticks = []\n            \n            #To reassign three var above\n            for tmp_id in range(hour_diff):\n                tmp_st = min_timestamp + tmp_id * 3600\n                #To transfer timestamp to datetime string\n                tmp_datetime = datetime.datetime.fromtimestamp(tmp_st)\n                tmp_datetime_str = tmp_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")\n                tmp_date_str = tmp_datetime_str[0:10]\n                tmp_hour_str = tmp_datetime_str[11:13]\n                date_all.append(tmp_date_str)\n                x_hour_list.append(tmp_hour_str)\n                '''\n                Below code is for handling y-axis's data\n                If there is no data at this hour,0.0 will be filled into\n                '''\n                if tmp_datetime_str in ori_datetime_str:\n                    tmp_index = ori_datetime_str[tmp_datetime_str]\n                    tmp_y_ticks.append(y_memory_list[tmp_index])\n                else:\n                    tmp_y_ticks.append(0.0)\n            y_memory_list = tmp_y_ticks\n            \n        #To store previous date string value as a reference data\n        pre_date_str = str(date_all[0])\n        \n        for dateIdx in range(len(date_all)):\n            # To get the data for the x-axis ticks\n            x_ticks.append(float('%0.1f' % dateIdx))\n            '''\n            Get the data for the lable of x-axis\n            If the label existed in the list x_ticks_lables,\n            put hour_str into x_ticks_lables \n            otherwise,put date_lables into x_ticks_lables\n            '''\n            hour_str = str(x_hour_list[dateIdx])\n            date_str = str(date_all[dateIdx])\n            x_lables = date_str + ' ' + hour_str\n            if (dateIdx == 0):\n                x_ticks_lables.append(x_lables)\n            else:#dateIdx > 0\n                if (pre_date_str == date_str):\n                    x_ticks_lables.append(hour_str)\n                else:\n                    pre_date_str = date_str\n                    x_ticks_lables.append(x_lables)\n        \n        #To declarea Sketchpad\n        fig = pl.figure()\n        #To declare an ax container as a drawing paper\n        ax = fig.add_subplot(111)\n        #To set the size of the Sketchpad depending on the size of the data\n        data_size = len(x_ticks)\n        if(data_size <= 20):\n            fig.set_size_inches(12,6)\n        elif(data_size <= 40):\n            fig.set_size_inches(16,6)\n        elif(data_size <= 60):\n            fig.set_size_inches(18,7)\n        elif(data_size <=100):\n            fig.set_size_inches(22,7)\n            \n        #To set the title/label/grid for the graph\n        figure_title = 'Memory Usage by Hour\\n'\n        pl.title(figure_title, fontsize = 14, fontweight = 'bold')\n        x_lable = 'Hours'\n        #To set x-axis label\n        pl.xlabel(x_lable)\n        #To set y-axis label\n        pl.ylabel(u'MEMORY_USAGE(GB)')\n        #To set grid line style according to your requirement\n        pl.grid(True, ls = '--', color = '#2c628b', alpha = 0.05)\n        pl.xticks(x_ticks, x_ticks_lables, rotation = 90)\n        \n        #To mark the data point \n        for id in range(len(y_memory_list)):\n            if(y_memory_list[id] == 0.0):#If no data,drawing a empty circle\n                pl.scatter(x_ticks[id], y_memory_list[id], c = '', marker = 'o', edgecolors = 'r', s = 50)\n            else:\n                pl.scatter(x_ticks[id], y_memory_list[id], c = '#2c628b') \n                pl.text(x_ticks[id], y_memory_list[id], '%.2f' % y_memory_list[id], fontsize = 9)\n        \n        #Below two variable is used for storeing magnified data\n        xnew_hour = []\n        ynew_memory = []\n        '''\n        if the size of data is greater than 2, showing a line not a scatter\n        otherwise, a scatter graph will be showed\n        '''\n        if(len(x_hour_list) >= 3):\n            ##In order to smooth the line chart,handle the data further##\n            #Expand each x axis data 20 times\n            xnew_hour = np.linspace(np.asarray(x_ticks).min(), np.asarray(x_ticks).max(), np.asarray(x_ticks).size*20) \n            #Handle the data of new y axis data\n            ynew_memory= spline(np.asarray(x_ticks), np.asarray(y_memory_list), xnew_hour)\n            ynew_memory_list = list(ynew_memory)\n            #No negative value for y-axis\n            for y_idx in range(len(ynew_memory_list)):\n                if (ynew_memory_list[y_idx] < 0.0):\n                    ynew_memory_list[y_idx] = 0.0\n            ynew_memory = np.asarray(ynew_memory_list)        \n            #Fill the gragh according to your requirement\n            pl.fill_between(xnew_hour, ynew_memory, where=(xnew_hour.min()<xnew_hour) & (xnew_hour<xnew_hour.max()), color = '#2c628b', alpha = 0.09)\n            #Draw curve graph\n            pl.plot(xnew_hour, ynew_memory, color = '#2c628b')\n            #Set y-axis value range according to your data\n            start_value=ynew_memory.min() -  ynew_memory.min() / 2\n            start_value=float('%.2f' % start_value)\n            end_value=ynew_memory.max() + ynew_memory.max() / 2\n            end_value=float('%.2f' % end_value)\n            #Set the scale for y-axis\n            pl.ylim(float('%.2f' % start_value),float('%.2f' % end_value))\n            #pl.yticks(np.linspace(start_value,end_value,0.1,endpoint=True))\n        pl.show()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom pandas.plotting import table\nimport numpy as np\n\ndates = pd.date_range('20130101',periods=6)\ndf = pd.DataFrame(np.random.randn(6,4),index=dates,columns=list('ABCD'))\n\ndf.index = [item.strftime('%Y-%m-%d') for item in df.index] # Format date\n\nfig, ax = plt.subplots(figsize=(30, 6)) # set size frame\nax.xaxis.set_visible(False)  # hide the x axis\nax.yaxis.set_visible(False)  # hide the y axis\nax.set_frame_on(False)  # no visible frame, uncomment if size is ok\ntabla = table(ax, df, loc='upper right', colWidths=[0.17]*len(df.columns))  # where df is your data frame\ntabla.auto_set_font_size(False) # Activate set fontsize manually\ntabla.set_fontsize(9) # if ++fontsize is necessary ++colWidths\ntabla.scale(2, 2) # change size table\nplt.show()\n#plt.savefig('table.png', transparent=True)"
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "ename": "SyntaxError", 
                    "evalue": "Missing parentheses in call to 'print' (<ipython-input-1-a54d707aa8d4>, line 16)", 
                    "traceback": [
                        "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-a54d707aa8d4>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    print 'dataframe_hour=\\n',dataframe_hour\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'\n"
                    ], 
                    "output_type": "error"
                }
            ], 
            "source": "#import the required lib\nimport numpy as np\nimport pylab as pl\nfrom scipy.interpolate import spline\n\n#To get all query conditions\nhandle_query_condition()\n\n#To get data and draw graph by data.\nif(ISOK_ALL_PARA and (REPORT_TYPE == 'ALL' or REPORT_TYPE == 'LOG')):\n    #Get data from the target database to assemble a data frame that will be used for the following graph\n    \n    sql_stst = \"select char(date(collected)) as date,hour(collected) as hours,dec(max(memory_pool_used_gb),17,2) as memory_usage_gb from IBM_DSM_VIEWS.MEM_DB_TOTAL_USED where dbconn_id='{DB_CONN_ID}' and collected >= '{START_TIME}' and collected < '{END_TIME}' group by date(collected),hour(collected) order by date,hours\"\n    \n    dataframe_hour = %sql select char(date(collected)) as date,hour(collected) as hours,dec(max(memory_pool_used_gb),17,2) as memory_usage_gb from IBM_DSM_VIEWS.MEM_DB_TOTAL_USED where dbconn_id='{DB_CONN_ID}' and collected >= '{START_TIME}' and collected < '{END_TIME}' group by date(collected),hour(collected) order by date,hours\n    print 'dataframe_hour=\\n',dataframe_hour\n    if dataframe_hour.empty:\n        print 'For MEMORY: The query result is empty, please check your query parameters.\\n'\n    else:\n        #Get the hour data as x-axis from the data frame and convert the data into a numpy array\n        x_hour = dataframe_hour['HOURS'].values #here x_hour is a numpy narray\n        #Get the memory_usage_gb data as y-axis from the data frame and convert the data into a numpy array\n        y_memory = dataframe_hour['MEMORY_USAGE_GB'].values\n        #Define a empty var x_ticks to store x-axis ticks(marks)\n        x_ticks = []\n        #Define a empty var x_ticks_lables to restore x-axis labels\n        x_ticks_lables = []\n        #Define a empty var y_ticks to store y-axis ticks(marks)\n        y_memory_list = list(y_memory)\n        \n        x_hour_list = list(x_hour) #here x_hour is a python list\n        date_all = list(dataframe_hour['DATE'].values)\n        \n        ori_datetime_str = get_original_datatime_str(date_all, x_hour_list)\n        \n        '''\n        When the data queried is not equal to the requirement. Filling missing data \n        into the list x_hour_list,date_all and y_memory_list.\n        '''\n        if (len(x_hour_list) < INTERVAL):\n            #Transfer datatime data into time tuple for getting its' timestamp\n            tm_tuple = time.strptime(START_TIME, '%Y-%m-%d %H:%M:%S')\n            min_timestamp = time.mktime(tm_tuple)\n            \n            tmp_tuple = time.strptime(END_TIME, '%Y-%m-%d %H:%M:%S')\n            max_timestamp = time.mktime(tmp_tuple)\n            \n            '''\n            Get the difference between the max_timestamp and min_timestamp \n            which will be used for gaining all date and hour including the missing\n            '''\n            hour_diff = int((max_timestamp - min_timestamp) / 3600)\n            # To clear date_all\n            date_all = []\n            # To clear x_hour_list\n            x_hour_list = []\n            # To declare a new list to store y_memory data temporarily\n            tmp_y_ticks = []\n            \n            #To reassign three var above\n            for tmp_id in range(hour_diff):\n                tmp_st = min_timestamp + tmp_id * 3600\n                #To transfer timestamp to datetime string\n                tmp_datetime = datetime.datetime.fromtimestamp(tmp_st)\n                tmp_datetime_str = tmp_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")\n                tmp_date_str = tmp_datetime_str[0:10]\n                tmp_hour_str = tmp_datetime_str[11:13]\n                date_all.append(tmp_date_str)\n                x_hour_list.append(tmp_hour_str)\n                '''\n                Below code is for handling y-axis's data\n                If there is no data at this hour,0.0 will be filled into\n                '''\n                if tmp_datetime_str in ori_datetime_str:\n                    tmp_index = ori_datetime_str[tmp_datetime_str]\n                    tmp_y_ticks.append(y_memory_list[tmp_index])\n                else:\n                    tmp_y_ticks.append(0.0)\n            y_memory_list = tmp_y_ticks\n            \n        #To store previous date string value as a reference data\n        pre_date_str = str(date_all[0])\n        \n        for dateIdx in range(len(date_all)):\n            # To get the data for the x-axis ticks\n            x_ticks.append(float('%0.1f' % dateIdx))\n            '''\n            Get the data for the lable of x-axis\n            If the label existed in the list x_ticks_lables,\n            put hour_str into x_ticks_lables \n            otherwise,put date_lables into x_ticks_lables\n            '''\n            hour_str = str(x_hour_list[dateIdx])\n            date_str = str(date_all[dateIdx])\n            x_lables = date_str + ' ' + hour_str\n            if (dateIdx == 0):\n                x_ticks_lables.append(x_lables)\n            else:#dateIdx > 0\n                if (pre_date_str == date_str):\n                    x_ticks_lables.append(hour_str)\n                else:\n                    pre_date_str = date_str\n                    x_ticks_lables.append(x_lables)\n        \n        #To declarea Sketchpad\n        fig = pl.figure()\n        #To declare an ax container as a drawing paper\n        ax = fig.add_subplot(111)\n        #To set the size of the Sketchpad depending on the size of the data\n        data_size = len(x_ticks)\n        if(data_size <= 20):\n            fig.set_size_inches(12,6)\n        elif(data_size <= 40):\n            fig.set_size_inches(16,6)\n        elif(data_size <= 60):\n            fig.set_size_inches(18,7)\n        elif(data_size <=100):\n            fig.set_size_inches(22,7)\n            \n        #To set the title/label/grid for the graph\n        figure_title = 'Memory Usage by Hour\\n'\n        pl.title(figure_title, fontsize = 14, fontweight = 'bold')\n        x_lable = 'Hours'\n        #To set x-axis label\n        pl.xlabel(x_lable)\n        #To set y-axis label\n        pl.ylabel(u'MEMORY_USAGE(GB)')\n        #To set grid line style according to your requirement\n        pl.grid(True, ls = '--', color = '#2c628b', alpha = 0.05)\n        pl.xticks(x_ticks, x_ticks_lables, rotation = 90)\n        \n        #To mark the data point \n        for id in range(len(y_memory_list)):\n            if(y_memory_list[id] == 0.0):#If no data,drawing a empty circle\n                pl.scatter(x_ticks[id], y_memory_list[id], c = '', marker = 'o', edgecolors = 'r', s = 50)\n            else:\n                pl.scatter(x_ticks[id], y_memory_list[id], c = '#2c628b') \n                pl.text(x_ticks[id], y_memory_list[id], '%.2f' % y_memory_list[id], fontsize = 9)\n        \n        #Below two variable is used for storeing magnified data\n        xnew_hour = []\n        ynew_memory = []\n        '''\n        if the size of data is greater than 2, showing a line not a scatter\n        otherwise, a scatter graph will be showed\n        '''\n        if(len(x_hour_list) >= 3):\n            ##In order to smooth the line chart,handle the data further##\n            #Expand each x axis data 20 times\n            xnew_hour = np.linspace(np.asarray(x_ticks).min(), np.asarray(x_ticks).max(), np.asarray(x_ticks).size*20) \n            #Handle the data of new y axis data\n            ynew_memory= spline(np.asarray(x_ticks), np.asarray(y_memory_list), xnew_hour)\n            ynew_memory_list = list(ynew_memory)\n            #No negative value for y-axis\n            for y_idx in range(len(ynew_memory_list)):\n                if (ynew_memory_list[y_idx] < 0.0):\n                    ynew_memory_list[y_idx] = 0.0\n            ynew_memory = np.asarray(ynew_memory_list)        \n            #Fill the gragh according to your requirement\n            pl.fill_between(xnew_hour, ynew_memory, where=(xnew_hour.min()<xnew_hour) & (xnew_hour<xnew_hour.max()), color = '#2c628b', alpha = 0.09)\n            #Draw curve graph\n            pl.plot(xnew_hour, ynew_memory, color = '#2c628b')\n            #Set y-axis value range according to your data\n            start_value=ynew_memory.min() -  ynew_memory.min() / 2\n            start_value=float('%.2f' % start_value)\n            end_value=ynew_memory.max() + ynew_memory.max() / 2\n            end_value=float('%.2f' % end_value)\n            #Set the scale for y-axis\n            pl.ylim(float('%.2f' % start_value),float('%.2f' % end_value))\n            #pl.yticks(np.linspace(start_value,end_value,0.1,endpoint=True))\n        pl.show()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}